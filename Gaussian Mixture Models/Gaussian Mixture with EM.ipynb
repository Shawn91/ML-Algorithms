{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.创建测试数据\n",
    "1. 定义 3 个二元高斯分布\n",
    "2. 从这 3 个高斯分布中分别产生  100+200+300=600 个数据点\n",
    "3. 作图展示这 600 个数据点\n",
    "\n",
    "## 1.1 定义 3 个二元高斯分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义每个高斯分布的平均数组成的 3*2 矩阵\n",
    "mean_matrix = torch.Tensor([\n",
    "    [1.2, 0.4],\n",
    "    [-4.4, 1.0],\n",
    "    [4.1, -0.3]\n",
    "])\n",
    "\n",
    "# 定义每个高斯分布的协方差矩阵\n",
    "covariance_matrix = torch.zeros([3,2,2])\n",
    "covariance_matrix[0] = torch.Tensor([[0.8, -0.4], [-0.4, 1.0]])\n",
    "covariance_matrix[1] = torch.Tensor([[1.2, -0.8], [-0.8, 1.0]])\n",
    "covariance_matrix[2] = torch.Tensor([[1.2, 0.6], [0.6, 3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians = [MultivariateNormal(mean, covariance) for mean,covariance in zip(mean_matrix, covariance_matrix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 创建测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples=[100,200,300]):\n",
    "    samples = torch.Tensor()\n",
    "    for i in range(3):\n",
    "        gaussian = gaussians[i]\n",
    "        samples = torch.cat((samples, gaussian.rsample([n_samples[i]])))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(samples.numpy(), columns=['X', 'Y'])\n",
    "df['Gaussian'] = 0\n",
    "df.loc[100:300,'Gaussian'] = 1\n",
    "df.loc[300:600,'Gaussian'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='X', y='Y', hue='Gaussian', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM\n",
    "\n",
    "使用 EM 算法来估算 GMM 的参数。\n",
    "\n",
    "测试数据的 shape 为 `[600, 2]`\n",
    "\n",
    "1. e-step: 计算 $P(z_k=1|x)$。得到的是 shape 为 `[3, 600]`\n",
    "2. m-step: 计算 \n",
    "* new mean，尺寸为 `[3,2]`\n",
    "* new covariance，尺寸为 `[3,2,2]`\n",
    "* new mixing coefficients，尺寸为 `[3,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self):\n",
    "        self.num_gaussians = None\n",
    "        self.means, self.covs, self.mixing_coefs = [None] * 3\n",
    "\n",
    "    def initialize(self, num_gauss, num_dimens):\n",
    "        \"\"\"EM 算法可以使用 k-means 来做参数初始化；此处为了方便，采用随机初始化\"\"\"\n",
    "        mean_matrix = torch.rand([num_gauss, num_dimens])  # 3*2\n",
    "        covariance_matrix = torch.stack([self._cov(torch.rand([num_dimens, 10])) for i in range(num_gauss)])\n",
    "        mixing_coefs = torch.Tensor([1 / num_gauss] * num_gauss)\n",
    "        return mean_matrix, covariance_matrix, mixing_coefs\n",
    "\n",
    "    def fit(self, data, num_gaussians=3, max_iter=500):\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.means, self.covs, self.mixing_coefs = self.initialize(num_gaussians, data.shape[1])\n",
    "        log_likelihoods = []\n",
    "        for i in range(max_iter):\n",
    "            log_likelihoods.append(self.log_likelihood(data, self.means, self.covs, self.mixing_coefs))\n",
    "            print(i, log_likelihoods[-1])\n",
    "            responsibilities = self.e_step(data, self.means, self.covs, self.mixing_coefs)\n",
    "            self.means, self.covs, self.mixing_coefs = self.m_step(data, responsibilities)\n",
    "\n",
    "    def e_step(self, data, means, covs, mixing_coefs):\n",
    "        responsibilities = [None] * len(mixing_coefs)\n",
    "        for i in range(len(mixing_coefs)):\n",
    "            responsibilities[i] = (self._cal_prob(means[i], covs[i], data=data).T * mixing_coefs[i]).squeeze()\n",
    "        responsibilities = torch.stack(responsibilities)\n",
    "        responsibilities = self._normalize(responsibilities)\n",
    "        return responsibilities\n",
    "\n",
    "    def m_step(self, data, responsibilities):\n",
    "        n_k = responsibilities.sum(1).view(self.num_gaussians, 1)  # n_k 为 3*1\n",
    "        new_mean = 1 / n_k * torch.mm(responsibilities, data)  # 3*2\n",
    "\n",
    "        # 如下操作有点复杂。实际上不需要 for 循环最后再 stack，但是这样相对比较好理解\n",
    "        new_cov = [None] * self.num_gaussians\n",
    "        for i in range(self.num_gaussians):\n",
    "            data_minus_mean = (data - new_mean[i]).view((data.shape[0], data.shape[1], -1))  # 600*2*1\n",
    "            responsibility = torch.unsqueeze(responsibilities[i], 0).T.view((data.shape[0], 1, 1))  # 600*1*1\n",
    "            new_cov[i] = torch.bmm(data_minus_mean, data_minus_mean.transpose(1, 2))  # 600*2*2\n",
    "            new_cov[i] = (new_cov[i] * responsibility).sum(dim=0)  # 2*2\n",
    "            new_cov[i] = new_cov[i] / n_k[i].item()\n",
    "        new_cov = torch.stack(new_cov)  # 3*2*2\n",
    "\n",
    "        new_mixing_coefficients = n_k / self.num_gaussians  # 3*1\n",
    "\n",
    "        return new_mean, new_cov, new_mixing_coefficients\n",
    "\n",
    "    def log_likelihood(self, data, means, covs, mixing_coefs):\n",
    "        likelihood = torch.zeros([data.shape[0], 1])  # 600*1\n",
    "        for i in range(len(mixing_coefs)):\n",
    "            l = self._cal_prob(means[i].view([-1, data.shape[1]]), covs[i].view([-1, data.shape[1]]), data=data)\n",
    "            likelihood += l * mixing_coefs[i].item()\n",
    "        log_likelihood = likelihood.log()\n",
    "        log_likelihood = torch.clamp(log_likelihood, 1e-6)\n",
    "        log_likelihood = torch.sum(log_likelihood)\n",
    "        return log_likelihood\n",
    "\n",
    "    def _cov(self, m):\n",
    "        m_exp = torch.mean(m, dim=1)\n",
    "        x = m - m_exp[:, None]\n",
    "        cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
    "        return cov\n",
    "\n",
    "    def _cal_prob(self, mean, cov, data):\n",
    "        \"\"\"给定一个高斯分布，以及一批数据，计算每一条数据来自这个高斯分布的概率\"\"\"\n",
    "        # data : 600*1*2; mean: 1*2; cov: 2*2\n",
    "        data = data.view([data.shape[0], 1, data.shape[1]])\n",
    "        data_minus_mean = data - mean  # 600*1*2\n",
    "        denominator = (-0.5*torch.bmm(data_minus_mean @ cov.inverse(), data_minus_mean.transpose(1,2))).exp()\n",
    "        numerator = ((2 * pi) ** (data.shape[0] / 2)) * torch.sqrt(torch.det(cov)).item()\n",
    "        return denominator.view([data.shape[0], 1]) / numerator\n",
    "\n",
    "    def _normalize(self, data):\n",
    "        \"\"\"给定 M*N 的数据 data，对行求和，然后 data 中每个元素除以所在行的和\"\"\"\n",
    "        axis_sums = data.sum(1)\n",
    "        axis_sums = axis_sums.view([axis_sums.shape[0], 1])\n",
    "        return data / axis_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GMM()\n",
    "g.fit(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
